# Projeto de Pipeline de Dados de E-commerce no Azure

![Azure](https://img.shields.io/badge/Azure-0078D4?style=for-the-badge&logo=microsoftazure&logoColor=white)
![Databricks](https://img.shields.io/badge/Databricks-FF3621?style=for-the-badge&logo=databricks&logoColor=white)
![Synapse](https://img.shields.io/badge/Azure%20Synapse-62B5E5?style=for-the-badge&logo=microsoftazure&logoColor=white)
![Power BI](https://img.shields.io/badge/Power%20BI-F2C811?style=for-the-badge&logo=powerbi&logoColor=black)

**Status do Projeto: Conclu√≠do ‚úÖ**

## üéØ Objetivo

Este projeto demonstra a constru√ß√£o de uma plataforma de dados completa e moderna na nuvem **Microsoft Azure**. O objetivo foi simular um ambiente de e-commerce, ingerindo, processando e transformando dados transacionais para, ao final, gerar insights estrat√©gicos e apoiar a tomada de decis√£o atrav√©s de um dashboard interativo.

O pipeline foi projetado para responder a perguntas de neg√≥cio cruciais, como:
-   Qual a receita total gerada m√™s a m√™s?
-   Quais s√£o os produtos mais vendidos?
-   Qual a performance log√≠stica? O SLA de entrega est√° sendo cumprido por regi√£o?
-   Quais os meios de pagamento mais utilizados pelos clientes?

## üèõÔ∏è Arquitetura da Solu√ß√£o

A solu√ß√£o foi constru√≠da utilizando a **Arquitetura Medallion**, um padr√£o de design que garante a qualidade, governan√ßa e organiza√ß√£o dos dados em camadas (Bronze, Silver e Gold), aumentando progressivamente o valor da informa√ß√£o.

<br>

_**[INSERIR SEU DIAGRAMA DE ARQUITETURA AQUI]**_

*Dica: Crie um diagrama em uma ferramenta como [diagrams.net](http://diagrams.net) ou Lucidchart, salve como PNG, fa√ßa o upload para uma pasta `/img` no seu reposit√≥rio e substitua este texto pelo link: `![Arquitetura](img/arquitetura.png)`*

<br>

## üõ†Ô∏è Tecnologias Utilizadas

-   **Nuvem:** Microsoft Azure
-   **Gera√ß√£o de Dados:** Python com a biblioteca Faker
-   **Armazenamento:** Azure Data Lake Storage Gen2
-   **Ingest√£o e Orquestra√ß√£o:** Azure Data Factory
-   **Transforma√ß√£o e Enriquecimento:** Azure Databricks (com PySpark)
-   **Camada de Servi√ßo (Serving Layer):** Azure Synapse Analytics (Serverless SQL Pool)
-   **Visualiza√ß√£o e BI:** Microsoft Power BI
-   **Versionamento de C√≥digo:** Git & GitHub

## üîÑ Fluxo do Pipeline

O pipeline de dados foi estruturado nas seguintes etapas:

#### 1. Gera√ß√£o de Dados Sint√©ticos
-   Um script **Python** com **Faker** foi desenvolvido para criar uma massa de dados realista, simulando transa√ß√µes de um e-commerce com tabelas de `clientes`, `pedidos`, `pagamentos` e `entregas`.

#### 2. Armazenamento e Estrutura (Data Lake)
-   O **Azure Data Lake Gen2** foi configurado como reposit√≥rio central, com containers para cada camada da Arquitetura Medallion:
    -   **RAW:** Recebe os dados brutos gerados pelo script (arquivos `.csv`).
    -   **BRONZE:** Armazena os mesmos dados, mas convertidos para um formato colunar otimizado (**Parquet**), representando a primeira etapa de ingest√£o.
    -   **SILVER:** Cont√©m os dados limpos, padronizados, enriquecidos e com regras de neg√≥cio aplicadas. As tabelas aqui s√£o normalizadas e prontas para consumo anal√≠tico.
    -   **GOLD:** Armazena tabelas agregadas e modeladas, prontas para responder √†s perguntas de neg√≥cio e alimentar o dashboard de BI.

#### 3. Ingest√£o e Orquestra√ß√£o (Azure Data Factory)
-   O **ADF** foi utilizado para orquestrar o primeiro movimento de dados: pegar os arquivos `.csv` da camada `raw`, convert√™-los para `.parquet` e deposit√°-los na camada `bronze`, automatizando a ingest√£o inicial.

#### 4. Transforma√ß√£o (Azure Databricks)
-   O cora√ß√£o do processamento. Notebooks em **PySpark** no **Databricks** foram utilizados para:
    -   Ler os dados da camada **Bronze**.
    -   Realizar a limpeza (tratamento de nulos, duplicados).
    -   Padronizar tipos de dados (especialmente datas).
    -   Enriquecer os dados, criando novas colunas com intelig√™ncia de neg√≥cio (ex: c√°lculo de atraso no SLA de entrega).
    -   Salvar as tabelas tratadas na camada **Silver**.

#### 5. Camada de Servi√ßo (Azure Synapse Analytics)
-   Com os dados limpos na camada Silver, o **Databricks** foi novamente utilizado para criar as agrega√ß√µes da camada **Gold**.
-   Em seguida, o **Synapse Analytics Serverless SQL Pool** foi conectado ao Data Lake para criar `VIEWs` sobre os arquivos Parquet da camada Gold. Isso disponibiliza os dados atrav√©s de um ponto de extremidade SQL padr√£o, de forma perform√°tica e segura, sem a necessidade de mover os dados.

#### 6. Visualiza√ß√£o (Power BI)
-   O **Power BI** foi conectado ao **Synapse Analytics** em modo **DirectQuery** para consumir os dados da camada Gold e apresentar os KPIs de neg√≥cio de forma visual e interativa.

## üìÅ Estrutura do Reposit√≥rio
-   **/01_Mount_ADLS.ipynb**: Notebook Databricks respons√°vel por montar o Data Lake no ambiente para facilitar o acesso aos dados.
-   **/02_Bronze_to_Silver.ipynb**: Notebook com o c√≥digo PySpark que l√™ os dados da camada Bronze, aplica as transforma√ß√µes e salva na camada Silver.
-   **/03_Silver_to_Gold.ipynb**: Notebook com o c√≥digo PySpark que l√™ os dados da camada Silver, cria as agrega√ß√µes e salva as tabelas anal√≠ticas na camada Gold.

## üìä Resultado Final: Dashboard de Neg√≥cios

O dashboard final consolida os principais indicadores de performance do e-commerce, permitindo uma an√°lise estrat√©gica e visual dos resultados.

<br>

_**[INSERIR PRINT DO SEU DASHBOARD FINAL DO POWER BI AQUI]**_

*Dica: Tire um print bonito do seu dashboard, fa√ßa o upload para a pasta `/img` e substitua este texto pelo link: `![Dashboard](img/dashboard.png)`*

<br>

## üë®‚Äçüíª Autor

**[Seu Nome Completo]**

-   **LinkedIn:** `[Link para o seu perfil do LinkedIn]`
-   **GitHub:** `[Link para o seu perfil do GitHub]`
